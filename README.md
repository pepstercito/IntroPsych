# IntroPsych Confidenceâ€“Accuracy Study (CG vs EG)

## ğŸ“‚ Repository Structure
```
IntroPsych/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ Psychology Study Results.xlsx
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ study_results_clean.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cleaning.py
â”‚   â”œâ”€â”€ scoring.py
â”‚   â””â”€â”€ stats.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_prep.ipynb
â”‚   â””â”€â”€ 02_analysis.ipynb
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ accuracy_by_group.png
â”‚   â”œâ”€â”€ abs_by_group.png
â”‚   â””â”€â”€ cws_by_group.png
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“˜ Project Overview

This project analyses whether the **Control Group (CG)** and **Experimental Group (EG)** differ in:

- **Raw accuracy**
- **ABS confidence-weighted score**
- **CWS confidence-weighted score**

The full pipeline covers:

1. Cleaning and standardising the raw Excel responses  
2. Applying three scoring methods  
3. Running statistical tests (one-tailed t-tests)  
4. Generating figures and tables for reporting  

Everything is fully reproducible and version-controlled.

---

## ğŸ§¹ Data Cleaning

Run the cleaning pipeline:

```bash
python -m src.cleaning
```

This script:

- Loads both CG and EG Excel sheets  
- Extracts correctness (0/1) and confidence (1â€“7) for 20 questions  
- Removes non-participant rows  
- Generates columns: `correct_i`, `conf_i`, `p_i`, `abs_i`, `cws_i`  
- Computes participant-level totals  
- Saves the processed dataset to:

```
data/processed/study_results_clean.csv
```

---

## ğŸ§® Scoring Methods

### **1. Raw Accuracy**
Simple proportion of correct answers.

### **2. ABS Score (Augmented Brier-like scoring)**
A confidence-weighted scoring method based on absolute distance:

- High-confidence correct â†’ strong reward  
- Guessed correct â†’ moderate reward  
- Low-confidence incorrect â†’ mild penalty  
- High-confidence incorrect â†’ strong penalty  

Implemented in `scoring.py`.

### **3. CWS Score (Confidence-Weighted Scoring)**
A stricter scoring system emphasising calibration:

- Correct + high confidence â†’ largest reward  
- Correct + low confidence â†’ smaller reward  
- Incorrect + low confidence â†’ minor penalty  
- Incorrect + high confidence â†’ largest penalty  

Also implemented in `scoring.py`.

---

## ğŸ“Š Statistical Analysis

The notebook:

```
notebooks/02_analysis.ipynb
```

produces:

- Summary statistics  
- Histograms of accuracy, confidence, ABS, CWS  
- Group comparison barplots (with 95% CI)  
- One-tailed independent samples t-tests  
- Effect sizes (Cohenâ€™s d)

Example output columns:

| score | CG mean | EG mean | t | p (one-tailed) | d |
|-------|---------|---------|---|----------------|---|

---

## ğŸ¯ Hypothesis

- **Hâ‚:** CG will perform better than EG (one-tailed)  
- **Hâ‚€:** No difference or EG performs equally/worse  

Analyses evaluate whether CG scores exceed EG scores across all three scoring methods.

---

## ğŸ“ˆ Figures

Figures are automatically saved to:

```
figures/
```

and include:

- `accuracy_by_group.png`
- `abs_by_group.png`
- `cws_by_group.png`

Each figure displays mean group scores with **95% CI error bars**.

---

## â–¶ï¸ Reproducibility Instructions

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Activate virtual environment

macOS / Linux:

```bash
source venv/bin/activate
```

### 3. Regenerate cleaned dataset

```bash
python -m src.cleaning
```

### 4. Run analysis notebooks

```bash
jupyter notebook
```

---

## ğŸ“ Notes

- All data is from the class experiment and contains only participant names as originally collected.  
- Entire pipeline is deterministic and reproducible via `cleaning.py` + the analysis notebooks.  
- Figures and processed CSVs are automatically regenerated.

---